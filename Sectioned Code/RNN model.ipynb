{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7688cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1785ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2382"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'FB.csv'\n",
    "meta = pd.read_csv(url)\n",
    "meta = meta.dropna(how='any',axis=0) #If there is missing data\n",
    "meta['Date'].apply(pd.to_datetime) #For ease of adjusting dates later on\n",
    "len(meta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6491497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[['Close'] + [col for col in meta if col not in ['Adj Close', 'Close']] + ['Adj Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3821c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.230000</td>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>42.049999</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>573576400</td>\n",
       "      <td>38.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.029999</td>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>36.660000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>168192700</td>\n",
       "      <td>34.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>2012-05-22</td>\n",
       "      <td>32.610001</td>\n",
       "      <td>33.590000</td>\n",
       "      <td>30.940001</td>\n",
       "      <td>101786600</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>31.370001</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>31.360001</td>\n",
       "      <td>73600000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.029999</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>32.950001</td>\n",
       "      <td>33.209999</td>\n",
       "      <td>31.770000</td>\n",
       "      <td>50237200</td>\n",
       "      <td>33.029999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Close        Date       Open       High        Low     Volume  \\\n",
       "0  38.230000  2012-05-18  42.049999  45.000000  38.000000  573576400   \n",
       "1  34.029999  2012-05-21  36.529999  36.660000  33.000000  168192700   \n",
       "2  31.000000  2012-05-22  32.610001  33.590000  30.940001  101786600   \n",
       "3  32.000000  2012-05-23  31.370001  32.500000  31.360001   73600000   \n",
       "4  33.029999  2012-05-24  32.950001  33.209999  31.770000   50237200   \n",
       "\n",
       "   Adj Close  \n",
       "0  38.230000  \n",
       "1  34.029999  \n",
       "2  31.000000  \n",
       "3  32.000000  \n",
       "4  33.029999  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.sort_values('Date')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2df0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2948e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_dims, layer_dims, num_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dims = hidden_dims #Numer of features in the hidden state\n",
    "        self.layer_dims = layer_dims #Number of recurrent layers\n",
    "        self.rnn = nn.RNN(num_inputs, hidden_dim, layer_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_outputs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h_0 = torch.zeros(self.layer_dim, X.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, h_0 = self.rnn(X, h_0.detach())\n",
    "        out = out[:,-1,:]\n",
    "        out.self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ea1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "num_input, hidden_dim, layer_dim, num_output = 14, 15, 2, 1\n",
    "rnn_model = RNN(num_input, hidden_dim, layer_dim, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d37d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sliding window data\n",
    "def sliding_window(data, timeframe):\n",
    "    numpydata = data.to_numpy() \n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(numpydata) - timeframe): \n",
    "        data.append(numpydata[index: index + timeframe])\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "sw_meta = sliding_window(meta.iloc[:,0:1], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33752e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.DataFrame(sw_meta.T.reshape(-1, 15))\n",
    "meta_data.columns = ['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5', 'Day 6', 'Day 7', 'Day 8', 'Day 9', 'Day 10', 'Day 11', 'Day 12', 'Day 13', 'Day 14', 'Target']\n",
    "meta_data = meta_data[['Target'] + [col for col in meta_data.columns if col != 'Target' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8422092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def feature_label_split(dataframe, target):\n",
    "    y = dataframe.iloc[:,0:1]\n",
    "    X = dataframe.iloc[:,1:]\n",
    "    return X, y\n",
    "\n",
    "def train_val_test_split(dataframe, target, test_ratio):\n",
    "    val_ratio = test_ratio / (1 - test_ratio)\n",
    "    X, y = feature_label_split(dataframe, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ratio, shuffle = False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = val_ratio, shuffle = False)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10100d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(meta_data, 'Target', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f73be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_array = scaler.fit_transform(X_train)\n",
    "X_val_array = scaler.transform(X_val)\n",
    "X_test_array = scaler.transform(X_test)\n",
    "\n",
    "y_train_array = scaler.fit_transform(y_train)\n",
    "y_val_array = scaler.transform(y_val)\n",
    "y_test_array = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e135a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_feat = torch.Tensor(X_train_array)\n",
    "train_targ = torch.Tensor(y_train_array)\n",
    "val_feat = torch.Tensor(X_val_array)\n",
    "val_targ = torch.Tensor(y_val_array)\n",
    "test_feat = torch.Tensor(X_test_array)\n",
    "test_targ = torch.Tensor(y_test_array)\n",
    "\n",
    "training_set = TensorDataset(train_feat, train_targ)\n",
    "valid_set = TensorDataset(val_feat, val_targ)\n",
    "test_set = TensorDataset(test_feat, test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833077fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 50\n",
    "train_dl = DataLoader(training_set, batch_size =  batch_size, drop_last = True)\n",
    "val_dl = DataLoader(valid_set, batch_size =  batch_size, drop_last = True)\n",
    "test_dl = DataLoader(test_set, batch_size =  batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5873903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimiser\n",
    "class Optimization():\n",
    "    def __init__(self, model, criterion, updater):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.updater = updater\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        \n",
    "        def training_step(self, inputs, labels):\n",
    "            self.model.train()\n",
    "            y_hat = self.model(inputs)\n",
    "            loss = self.criterion(labels, y_hat)\n",
    "            loss.backward()\n",
    "            self.updater.step()\n",
    "            self.updater.zero_grad()\n",
    "            return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c0465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "def RNN_model_trainer(self, train_dataloader, val_dataloader, batch_size, num_epochs, num_features):\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        batch_loss = []\n",
    "        for train_inputs, train_labels in train_loader:\n",
    "            train_inputs = train_inputs.view([batch_size, -1, num_features]).to(device)\n",
    "            train_labels = train_labels.to(device)\n",
    "            loss = self.training_step(train_inputs, train_labels)\n",
    "            batch_loss.append(loss)\n",
    "            training_loss = np.mean(batch_loss)\n",
    "            self.train_losses.append(training_loss)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_val_loss = []\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_inputs = val_inputs.view([batch_size, -1, num_features]).to(device)\n",
    "                    val_labels = val_labels.to(device)\n",
    "                    self.model.eval()\n",
    "                    y_hat = self.model(val_inputs)\n",
    "                    val_loss = criterion(val_labels, y_hat).item()\n",
    "                    batch_val_loss.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_loss)\n",
    "                self.valid_losses.append(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cf8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.2, 60\n",
    "criterion_3 = nn.MSELoss()\n",
    "updater_3 = torch.optim.SGD(rnn_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40a4963",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Optimization' object has no attribute 'RNN_model_trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m Optimization(model \u001b[38;5;241m=\u001b[39m rnn_model, criterion \u001b[38;5;241m=\u001b[39m criterion_3, updater \u001b[38;5;241m=\u001b[39m updater_3)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRNN_model_trainer\u001b[49m(train_dataloader \u001b[38;5;241m=\u001b[39m train_dl, val_dataloader \u001b[38;5;241m=\u001b[39m val_dl, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, num_epochs \u001b[38;5;241m=\u001b[39m num_epochs, num_features \u001b[38;5;241m=\u001b[39m num_input)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Optimization' object has no attribute 'RNN_model_trainer'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "opt = Optimization(model = rnn_model, criterion = criterion_3, updater = updater_3)\n",
    "opt.RNN_model_trainer(train_dataloader = train_dl, val_dataloader = val_dl, batch_size = 50, num_epochs = num_epochs, num_features = num_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394967c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_dim, num_hiddens, num_outputs):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.rnn = nn.RNN(hidden_dim, num_hiddens)\n",
    "        self.fc = nn.Linear(num_hiddens, num_outputs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        hidden_state = self.rnn(X)\n",
    "        output, hidden = self.rnn(hidden_state)\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_dims, layer_dims, num_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dims = hidden_dims #Numer of features in the hidden state\n",
    "        self.layer_dims = layer_dims #Number of recurrent layers\n",
    "        self.rnn = nn.RNN(num_inputs, hidden_dim, layer_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_outputs)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h_0 = torch.zeros(self.layer_dims, X.size(0), self.hidden_dims).requires_grad_() \n",
    "        #Initial state of hidden state\n",
    "        output, h_0 = self.rnn(X, h_0.detach())\n",
    "        assert torch.equal(output[-1,:,:], h_0.squeeze(0))\n",
    "        return self.fc(h_0.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "num_input, hidden_dim, layer_dim, num_output = 14, 15, 2, 1\n",
    "rnn_model = RNN(num_input, hidden_dim, layer_dim, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d86972",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.2, 60\n",
    "criterion_3 = nn.MSELoss()\n",
    "updater_3 = torch.optim.SGD(rnn_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db77944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and evaluation\n",
    "def log_rmse(model, inputs, labels, criterion):\n",
    "    clipped_preds = torch.clamp(model(inputs), 1, float('inf'))\n",
    "    rmse = torch.sqrt(criterion(torch.log(clipped_preds), torch.log(labels)))\n",
    "    return rmse.item()\n",
    "\n",
    "def RNN_model_trainer(model, train_dataloader, criterion, updater):\n",
    "    train_ls = []\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, train_data in enumerate(train_dataloader):\n",
    "            train_inputs, train_labels = train_data\n",
    "            updater.zero_grad()\n",
    "            y_hat = model(train_inputs).squeeze(1)\n",
    "            loss = criterion(y_hat, train_labels)\n",
    "            loss.backward()\n",
    "            updater.step()\n",
    "        train_loss.append(log_rmse(model, train_inputs, train_labels, criterion))\n",
    "    return train_ls\n",
    "\n",
    "def RNN_model_evaluater(model, test_dataloader, criterion):\n",
    "    test_ls = []\n",
    "    for i, test_data in enumerate(test_dataloader):\n",
    "        test_inputs, test_labels = test_data\n",
    "    test_loss.append(log_rmse(model, test_inputs, test_labels, criterion))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_trainer(rnn_model, train_dl, criterion_3, updater_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c279958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.hidden = nn.Linear(num_inputs + num_hiddens, num_hiddens)\n",
    "        self.out = nn.Linear(num_inputs + num_hiddens, num_outputs)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.hidden(combined)\n",
    "        output = self.out(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input, hidden_dim, num_output = 14, 10, 1\n",
    "rnn_model = RNN(num_input, hidden_dim, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d1a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f4026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a76f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try 3\n",
    "#RNN model class\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, embed_dim, num_hiddens, num_outputs):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Embedding(num_inputs, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, num_hiddens)\n",
    "        self.fc = nn.Linear(num_hiddens, num_outputs)\n",
    "        \n",
    "    def forward(self, price):\n",
    "        embedded = self.hidden(price)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ef90a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input, embed_dim, num_hidden, num_output = 14,5, 10, 1\n",
    "rnn_model = RNN(num_input, embed_dim, num_hidden, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d06f6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr, num_epochs = 0.01, 100\n",
    "updater_3 = optim.SGD(rnn_model.parameters(), lr = lr)\n",
    "criterion_3 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "410dc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(model, inputs, labels, criterion):\n",
    "    clipped_preds = torch.clamp(model(inputs), 1, float('inf'))\n",
    "    rmse = torch.sqrt(criterion(torch.log(clipped_preds), torch.log(labels)))\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad2e19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model trainer\n",
    "def RNN_model_trainer(model, train_dataloader, updater, criterion):\n",
    "    batch_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for train_inputs, train_labels in train_dataloader:\n",
    "            updater.zero_grad()\n",
    "            y_hat = model(train_inputs).squeeze(1)\n",
    "            loss = criterion(y_hat, train_labels)\n",
    "            loss.backward()\n",
    "            updater.step()\n",
    "        train_ls.append(log_rmse(model, train_inputs, train_labels, crtierion))\n",
    "    return train_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47b7c6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m titit \u001b[38;5;241m=\u001b[39m \u001b[43mRNN_model_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_3\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mRNN_model_trainer\u001b[1;34m(model, train_dataloader, updater, criterion)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_inputs, train_labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m      6\u001b[0m     updater\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_hat, train_labels)\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, price)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, price):\n\u001b[1;32m---> 13\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embedded)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:], hidden\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "titit = RNN_model_trainer(rnn_model, train_dl, updater_3, criterion_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb04559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3101b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "662d8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try 4\n",
    "#RNN model \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.hidden = nn.Linear(num_inputs + num_hiddens, num_hiddens) \n",
    "        #Hidden layer includes information from both inputs and hidden layer itself\n",
    "        self.out = nn.Linear(num_inputs + num_hiddens, num_outputs)\n",
    "    \n",
    "    #Forward step with the hidden state\n",
    "    def forward(self, X, hidden_state):\n",
    "        combined = torch.cat((X, hidden_state), 1) \n",
    "        hidden = torch.sigmoid(self.hidden(combined))\n",
    "        output = self.out(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    #Initialising hidden state\n",
    "    def init_hidden(self):\n",
    "        return torch.nn.init.xavier_normal_(self.hidden.weight, gain = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfddab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input, num_hidden, num_output = 14, 10, 1\n",
    "rnn_model = RNN(num_input, num_hidden, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbd6c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.2, 60\n",
    "criterion_3 = nn.MSELoss()\n",
    "updater_3 = torch.optim.SGD(rnn_model.parameters(), lr = lr, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dbe73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "def RNN_model_trainer(model, dataloader, criterion, updater):\n",
    "    train_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            hidden_state = model.init_hidden() \n",
    "            updater.zero_grad()\n",
    "            for i in inputs:\n",
    "                y_hat, hidden_state = model(i, hidden_state)\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            updater.step()\n",
    "        train_loss.append(log_rmse(model, inputs, labels, criterion))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "301b0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set = train_test_split(meta, test_size = 0.2, shuffle = False)\n",
    "\n",
    "train_array = training_set.iloc[:,0:1]\n",
    "test_array = test_set.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8f6fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sliding window data\n",
    "def sliding_window(values, window_size):\n",
    "    dataset = []\n",
    "    if len(values) < window_size:\n",
    "        return values.values\n",
    "    for i in range(len(values)):\n",
    "        dataset.append(values[i:i+window_size])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c7d5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, timeframe):\n",
    "    numpydata = data.to_numpy() \n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(numpydata) - timeframe): \n",
    "        data.append(numpydata[index: index + timeframe])\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6677ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training = sliding_window(train_array, 16)\n",
    "rnn_testing = sliding_window(test_array, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ee5a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class trainingdataset(Dataset):\n",
    "    def __init__(self): #Loading in the data\n",
    "        xy = rnn_training\n",
    "        self.x = torch.from_numpy(xy[:,0:-2].astype(np.float32)) #Slice the first 14 values for the inputs\n",
    "        self.y =  torch.from_numpy(xy[:,[-1]].astype(np.float32)) #15th value for the labels\n",
    "        self.samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acd3904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testingdataset(Dataset):\n",
    "    def __init__(self): #Loading in the data\n",
    "        xy = rnn_testing\n",
    "        self.x = torch.from_numpy(xy[:,0:-2].astype(np.float32))\n",
    "        self.y =  torch.from_numpy(xy[:,[-1]].astype(np.float32))\n",
    "        self.samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8afa146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = trainingdataset()\n",
    "batch_size = 50\n",
    "train_dl = DataLoader(dataset = training, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "testing = testingdataset()\n",
    "test_dl = DataLoader(dataset = testing, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "395f6ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 14 but got size 10 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mRNN_model_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater_3\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mRNN_model_trainer\u001b[1;34m(model, dataloader, criterion, updater)\u001b[0m\n\u001b[0;32m      8\u001b[0m updater\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m---> 10\u001b[0m     y_hat, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_hat, labels)\n\u001b[0;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, X, hidden_state)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, hidden_state):\n\u001b[1;32m---> 13\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     14\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden(combined))\n\u001b[0;32m     15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(combined)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 10 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "RNN_model_trainer(rnn_model, train_dl, criterion_3, updater_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ffe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c432e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee33bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try 5\n",
    "#RNN model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        #Defining the RNN layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c2cd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input, num_hidden, num_output, no_layer = 14, 10, 1, 1\n",
    "rnn_model = Model(num_input, num_hidden, num_output, no_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e1bf987",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_3 = nn.MSELoss()\n",
    "updater_3 = torch.optim.SGD(rnn_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c5cbdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Day 1</th>\n",
       "      <th>Day 2</th>\n",
       "      <th>Day 3</th>\n",
       "      <th>Day 4</th>\n",
       "      <th>Day 5</th>\n",
       "      <th>Day 6</th>\n",
       "      <th>Day 7</th>\n",
       "      <th>Day 8</th>\n",
       "      <th>Day 9</th>\n",
       "      <th>Day 10</th>\n",
       "      <th>Day 11</th>\n",
       "      <th>Day 12</th>\n",
       "      <th>Day 13</th>\n",
       "      <th>Day 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.100000</td>\n",
       "      <td>38.230000</td>\n",
       "      <td>34.029999</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>33.029999</td>\n",
       "      <td>31.910000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>27.719999</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>25.870001</td>\n",
       "      <td>26.809999</td>\n",
       "      <td>26.309999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.100000</td>\n",
       "      <td>27.010000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>28.290001</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>31.410000</td>\n",
       "      <td>31.910000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>33.049999</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>32.230000</td>\n",
       "      <td>31.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.750000</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>31.200001</td>\n",
       "      <td>31.469999</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>32.169998</td>\n",
       "      <td>31.469999</td>\n",
       "      <td>30.969999</td>\n",
       "      <td>30.809999</td>\n",
       "      <td>30.719999</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>28.090000</td>\n",
       "      <td>29.110001</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>28.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.600000</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>23.709999</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>21.709999</td>\n",
       "      <td>20.879999</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>21.090000</td>\n",
       "      <td>21.920000</td>\n",
       "      <td>20.719999</td>\n",
       "      <td>20.719999</td>\n",
       "      <td>21.010000</td>\n",
       "      <td>21.809999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.730000</td>\n",
       "      <td>20.379999</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>19.049999</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>19.160000</td>\n",
       "      <td>19.440001</td>\n",
       "      <td>19.440001</td>\n",
       "      <td>19.410000</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.090000</td>\n",
       "      <td>18.059999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>361.609985</td>\n",
       "      <td>341.660004</td>\n",
       "      <td>346.230011</td>\n",
       "      <td>351.190002</td>\n",
       "      <td>369.790009</td>\n",
       "      <td>372.459991</td>\n",
       "      <td>367.809998</td>\n",
       "      <td>373.279999</td>\n",
       "      <td>358.320007</td>\n",
       "      <td>356.299988</td>\n",
       "      <td>351.950012</td>\n",
       "      <td>351.239990</td>\n",
       "      <td>358.920013</td>\n",
       "      <td>362.970001</td>\n",
       "      <td>363.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>380.660004</td>\n",
       "      <td>361.130005</td>\n",
       "      <td>359.959991</td>\n",
       "      <td>362.649994</td>\n",
       "      <td>363.179993</td>\n",
       "      <td>366.559998</td>\n",
       "      <td>358.450012</td>\n",
       "      <td>355.450012</td>\n",
       "      <td>355.119995</td>\n",
       "      <td>359.369995</td>\n",
       "      <td>363.350006</td>\n",
       "      <td>365.510010</td>\n",
       "      <td>368.390015</td>\n",
       "      <td>364.380005</td>\n",
       "      <td>372.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>357.480011</td>\n",
       "      <td>379.380005</td>\n",
       "      <td>382.049988</td>\n",
       "      <td>375.279999</td>\n",
       "      <td>376.260010</td>\n",
       "      <td>382.179993</td>\n",
       "      <td>377.570007</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>376.510010</td>\n",
       "      <td>376.529999</td>\n",
       "      <td>373.920013</td>\n",
       "      <td>373.059998</td>\n",
       "      <td>364.720001</td>\n",
       "      <td>355.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>323.769989</td>\n",
       "      <td>343.209991</td>\n",
       "      <td>345.959991</td>\n",
       "      <td>352.959991</td>\n",
       "      <td>353.579987</td>\n",
       "      <td>340.649994</td>\n",
       "      <td>339.609985</td>\n",
       "      <td>339.390015</td>\n",
       "      <td>343.010010</td>\n",
       "      <td>326.230011</td>\n",
       "      <td>332.959991</td>\n",
       "      <td>333.640015</td>\n",
       "      <td>329.220001</td>\n",
       "      <td>330.049988</td>\n",
       "      <td>325.450012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>328.079987</td>\n",
       "      <td>324.540009</td>\n",
       "      <td>328.529999</td>\n",
       "      <td>324.760010</td>\n",
       "      <td>335.339996</td>\n",
       "      <td>339.989990</td>\n",
       "      <td>340.779999</td>\n",
       "      <td>341.880005</td>\n",
       "      <td>324.609985</td>\n",
       "      <td>328.690002</td>\n",
       "      <td>315.809998</td>\n",
       "      <td>312.220001</td>\n",
       "      <td>316.920013</td>\n",
       "      <td>323.570007</td>\n",
       "      <td>329.980011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2367 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target       Day 1       Day 2       Day 3       Day 4       Day 5  \\\n",
       "0      27.100000   38.230000   34.029999   31.000000   32.000000   33.029999   \n",
       "1      31.100000   27.010000   27.400000   27.270000   28.290001   30.010000   \n",
       "2      28.750000   30.770000   31.200001   31.469999   31.730000   32.169998   \n",
       "3      21.600000   28.450001   29.340000   26.850000   23.709999   23.150000   \n",
       "4      17.730000   20.379999   21.200001   19.870001   19.049999   20.010000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2362  361.609985  341.660004  346.230011  351.190002  369.790009  372.459991   \n",
       "2363  380.660004  361.130005  359.959991  362.649994  363.179993  366.559998   \n",
       "2364  357.480011  379.380005  382.049988  375.279999  376.260010  382.179993   \n",
       "2365  323.769989  343.209991  345.959991  352.959991  353.579987  340.649994   \n",
       "2366  328.079987  324.540009  328.529999  324.760010  335.339996  339.989990   \n",
       "\n",
       "           Day 6       Day 7       Day 8       Day 9      Day 10      Day 11  \\\n",
       "0      31.910000   28.840000   28.190001   29.600000   27.719999   26.900000   \n",
       "1      31.410000   31.910000   31.600000   31.840000   33.049999   32.060001   \n",
       "2      31.469999   30.969999   30.809999   30.719999   28.250000   28.090000   \n",
       "3      21.709999   20.879999   20.040001   21.090000   21.920000   20.719999   \n",
       "4      19.160000   19.440001   19.440001   19.410000   19.150000   19.340000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2362  367.809998  373.279999  358.320007  356.299988  351.950012  351.239990   \n",
       "2363  358.450012  355.450012  355.119995  359.369995  363.350006  365.510010   \n",
       "2364  377.570007  378.000000  378.690002  376.510010  376.529999  373.920013   \n",
       "2365  339.609985  339.390015  343.010010  326.230011  332.959991  333.640015   \n",
       "2366  340.779999  341.880005  324.609985  328.690002  315.809998  312.220001   \n",
       "\n",
       "          Day 12      Day 13      Day 14  \n",
       "0      25.870001   26.809999   26.309999  \n",
       "1      33.099998   32.230000   31.360001  \n",
       "2      29.110001   29.000000   28.760000  \n",
       "3      20.719999   21.010000   21.809999  \n",
       "4      19.100000   19.090000   18.059999  \n",
       "...          ...         ...         ...  \n",
       "2362  358.920013  362.970001  363.510010  \n",
       "2363  368.390015  364.380005  372.630005  \n",
       "2364  373.059998  364.720001  355.700012  \n",
       "2365  329.220001  330.049988  325.450012  \n",
       "2366  316.920013  323.570007  329.980011  \n",
       "\n",
       "[2367 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c672d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train = meta_data.iloc[:,0:1].values\n",
    "rnn_target = meta_data.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5899a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.from_numpy(rnn_train)\n",
    "target_seq = torch.from_numpy(rnn_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55747b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m     updater_3\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Clears existing gradients from previous epoch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     input_seq\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[0;32m      4\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m model(input_seq)\n\u001b[0;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion_3(output, target_seq\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    updater_3.zero_grad() # Clears existing gradients from previous epoch\n",
    "    input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion_3(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    updater_3.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f49dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
